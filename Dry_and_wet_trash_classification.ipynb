{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, array_to_img\n",
    "from keras.layers import Conv2D, Flatten, MaxPooling2D, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the data\n",
    "DATADIR = \".//Data\"\n",
    "CATEGORIES = [\"solid\", \"wet\"]\n",
    "for category in CATEGORIES:\n",
    "# create path to cars and trucks\n",
    "    path = os.path.join(DATADIR,category)  \n",
    "# iterate over each image per cars and trucks\n",
    "    for img in os.listdir(path):\n",
    "# convert to array\n",
    "        img_array = cv2.imread(os.path.join(path,img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create training data\n",
    "IMG_SIZE = 80\n",
    "training_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create traing data\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:  # do cars and trucks\n",
    "\n",
    "        path = os.path.join(DATADIR,category)  # create path to cars and trucks\n",
    "        class_num = CATEGORIES.index(category)  # get the classification  (0 or a 1). 0=solid 1=wet\n",
    "\n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image cars and trucks\n",
    "            try:\n",
    "        # convert to array\n",
    "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)  \n",
    "                # resize to normalize data size\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                pass\n",
    "\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create features and labels\n",
    "import random\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X_wet_solid = []\n",
    "y_wet_solid = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X_wet_solid.append(features)\n",
    "    y_wet_solid.append(label)\n",
    "\n",
    "X_wet_solid = np.array(X_wet_solid).reshape(-1,\n",
    "                        IMG_SIZE, IMG_SIZE,\n",
    "                        1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##write the pickle file\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X_wet_solid.pickle\",\"wb\")\n",
    "pickle.dump(X_wet_solid, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y_wet_solid.pickle\",\"wb\")\n",
    "pickle.dump(y_wet_solid, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##divide training and testing dataset\n",
    "import pickle\n",
    "import numpy\n",
    "\n",
    "# -------------Load X--------------\n",
    "pickle_in = open(\"X_wet_solid.pickle\",\"rb\") \n",
    "train_images = pickle.load(pickle_in)\n",
    "# Split part of X for testing purpose\n",
    "test_images = train_images[int(0.9 * len(train_images)):]\n",
    "train_images = train_images[:int(0.9 * len(train_images))]\n",
    "\n",
    "# -------------Load y--------------\n",
    "pickle_in = open(\"y_wet_solid.pickle\",\"rb\") \n",
    "train_labels = pickle.load(pickle_in)\n",
    "#Split part of Y for testing purpose\n",
    "test_labels = train_labels[int(0.9 * len(train_labels)):]\n",
    "train_labels = numpy.asarray(train_labels[:int(0.9 * len(train_labels))])\n",
    "\n",
    "# convert list to ndarray, and reshape the labels\n",
    "test_labels = numpy.array(test_labels).reshape(len(test_labels),1)\n",
    "train_labels = numpy.array(train_labels).reshape(len(train_labels),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images - Type: <class 'numpy.ndarray'>, Shape (8998, 80, 80, 1)\n",
      "test_images - Type: <class 'numpy.ndarray'>, Shape (1000, 80, 80, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_images - Type: {type(train_images)}, Shape {train_images.shape}\")\n",
    "print(f\"test_images - Type: {type(test_images)}, Shape {test_images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[255],\n",
       "         [255],\n",
       "         [255],\n",
       "         ...,\n",
       "         [255],\n",
       "         [255],\n",
       "         [255]],\n",
       "\n",
       "        [[255],\n",
       "         [255],\n",
       "         [255],\n",
       "         ...,\n",
       "         [255],\n",
       "         [255],\n",
       "         [255]],\n",
       "\n",
       "        [[255],\n",
       "         [255],\n",
       "         [255],\n",
       "         ...,\n",
       "         [255],\n",
       "         [255],\n",
       "         [255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255],\n",
       "         [255],\n",
       "         [250],\n",
       "         ...,\n",
       "         [255],\n",
       "         [255],\n",
       "         [255]],\n",
       "\n",
       "        [[255],\n",
       "         [255],\n",
       "         [255],\n",
       "         ...,\n",
       "         [255],\n",
       "         [255],\n",
       "         [255]],\n",
       "\n",
       "        [[255],\n",
       "         [255],\n",
       "         [252],\n",
       "         ...,\n",
       "         [255],\n",
       "         [255],\n",
       "         [255]]],\n",
       "\n",
       "\n",
       "       [[[221],\n",
       "         [219],\n",
       "         [216],\n",
       "         ...,\n",
       "         [130],\n",
       "         [130],\n",
       "         [128]],\n",
       "\n",
       "        [[223],\n",
       "         [221],\n",
       "         [218],\n",
       "         ...,\n",
       "         [130],\n",
       "         [130],\n",
       "         [130]],\n",
       "\n",
       "        [[221],\n",
       "         [220],\n",
       "         [220],\n",
       "         ...,\n",
       "         [130],\n",
       "         [130],\n",
       "         [129]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[242],\n",
       "         [241],\n",
       "         [241],\n",
       "         ...,\n",
       "         [152],\n",
       "         [151],\n",
       "         [151]],\n",
       "\n",
       "        [[244],\n",
       "         [244],\n",
       "         [242],\n",
       "         ...,\n",
       "         [152],\n",
       "         [153],\n",
       "         [153]],\n",
       "\n",
       "        [[246],\n",
       "         [244],\n",
       "         [242],\n",
       "         ...,\n",
       "         [153],\n",
       "         [153],\n",
       "         [153]]],\n",
       "\n",
       "\n",
       "       [[[225],\n",
       "         [233],\n",
       "         [230],\n",
       "         ...,\n",
       "         [132],\n",
       "         [111],\n",
       "         [122]],\n",
       "\n",
       "        [[230],\n",
       "         [232],\n",
       "         [224],\n",
       "         ...,\n",
       "         [145],\n",
       "         [125],\n",
       "         [126]],\n",
       "\n",
       "        [[222],\n",
       "         [222],\n",
       "         [221],\n",
       "         ...,\n",
       "         [118],\n",
       "         [122],\n",
       "         [118]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[216],\n",
       "         [219],\n",
       "         [225],\n",
       "         ...,\n",
       "         [195],\n",
       "         [189],\n",
       "         [176]],\n",
       "\n",
       "        [[214],\n",
       "         [216],\n",
       "         [217],\n",
       "         ...,\n",
       "         [187],\n",
       "         [182],\n",
       "         [179]],\n",
       "\n",
       "        [[210],\n",
       "         [205],\n",
       "         [215],\n",
       "         ...,\n",
       "         [210],\n",
       "         [212],\n",
       "         [202]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[146],\n",
       "         [146],\n",
       "         [144],\n",
       "         ...,\n",
       "         [158],\n",
       "         [158],\n",
       "         [159]],\n",
       "\n",
       "        [[146],\n",
       "         [146],\n",
       "         [144],\n",
       "         ...,\n",
       "         [158],\n",
       "         [158],\n",
       "         [159]],\n",
       "\n",
       "        [[145],\n",
       "         [144],\n",
       "         [145],\n",
       "         ...,\n",
       "         [198],\n",
       "         [158],\n",
       "         [157]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[150],\n",
       "         [148],\n",
       "         [146],\n",
       "         ...,\n",
       "         [ 48],\n",
       "         [ 48],\n",
       "         [ 49]],\n",
       "\n",
       "        [[153],\n",
       "         [149],\n",
       "         [148],\n",
       "         ...,\n",
       "         [ 49],\n",
       "         [ 49],\n",
       "         [ 49]],\n",
       "\n",
       "        [[155],\n",
       "         [149],\n",
       "         [148],\n",
       "         ...,\n",
       "         [ 49],\n",
       "         [ 49],\n",
       "         [ 49]]],\n",
       "\n",
       "\n",
       "       [[[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]],\n",
       "\n",
       "        [[  0],\n",
       "         [  0],\n",
       "         [  0],\n",
       "         ...,\n",
       "         [  0],\n",
       "         [  0],\n",
       "         [  0]]],\n",
       "\n",
       "\n",
       "       [[[248],\n",
       "         [218],\n",
       "         [193],\n",
       "         ...,\n",
       "         [191],\n",
       "         [189],\n",
       "         [190]],\n",
       "\n",
       "        [[254],\n",
       "         [226],\n",
       "         [183],\n",
       "         ...,\n",
       "         [165],\n",
       "         [193],\n",
       "         [195]],\n",
       "\n",
       "        [[152],\n",
       "         [229],\n",
       "         [190],\n",
       "         ...,\n",
       "         [189],\n",
       "         [193],\n",
       "         [192]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[204],\n",
       "         [168],\n",
       "         [ 11],\n",
       "         ...,\n",
       "         [163],\n",
       "         [ 39],\n",
       "         [ 17]],\n",
       "\n",
       "        [[253],\n",
       "         [171],\n",
       "         [  6],\n",
       "         ...,\n",
       "         [ 10],\n",
       "         [ 10],\n",
       "         [ 13]],\n",
       "\n",
       "        [[254],\n",
       "         [167],\n",
       "         [  8],\n",
       "         ...,\n",
       "         [ 18],\n",
       "         [ 18],\n",
       "         [ 19]]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import package\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixRandomSeed in action\n"
     ]
    }
   ],
   "source": [
    "## set the randomseed\n",
    "from DL_tools import fixRandomSeed as frs\n",
    "frs.fixRandomSeed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wet_solid = Sequential([\n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(train_images.shape[1:])),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "\n",
    "    Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "    \n",
    "    Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'),\n",
    "    MaxPooling2D(pool_size=2),\n",
    "\n",
    "    Flatten(),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "\n",
    "    Dense(2, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Compile the model\n",
    "model_wet_solid.compile(optimizer='adam',\n",
    "              loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "282/282 [==============================] - 47s 167ms/step - loss: 0.1928 - accuracy: 0.9238 - val_loss: 0.1737 - val_accuracy: 0.9310\n",
      "Epoch 2/10\n",
      "282/282 [==============================] - 48s 169ms/step - loss: 0.1440 - accuracy: 0.9430 - val_loss: 0.1425 - val_accuracy: 0.9470\n",
      "Epoch 3/10\n",
      "282/282 [==============================] - 47s 166ms/step - loss: 0.1089 - accuracy: 0.9590 - val_loss: 0.1355 - val_accuracy: 0.9490\n",
      "Epoch 4/10\n",
      "282/282 [==============================] - 51s 180ms/step - loss: 0.0858 - accuracy: 0.9690 - val_loss: 0.1287 - val_accuracy: 0.9520\n",
      "Epoch 5/10\n",
      "282/282 [==============================] - 50s 175ms/step - loss: 0.0736 - accuracy: 0.9725 - val_loss: 0.1027 - val_accuracy: 0.9630\n",
      "Epoch 6/10\n",
      "282/282 [==============================] - 46s 164ms/step - loss: 0.0540 - accuracy: 0.9796 - val_loss: 0.1051 - val_accuracy: 0.9670\n",
      "Epoch 7/10\n",
      "282/282 [==============================] - 46s 165ms/step - loss: 0.0412 - accuracy: 0.9848 - val_loss: 0.1085 - val_accuracy: 0.9700\n",
      "Epoch 8/10\n",
      "282/282 [==============================] - 46s 163ms/step - loss: 0.0351 - accuracy: 0.9870 - val_loss: 0.1553 - val_accuracy: 0.9550\n",
      "Epoch 9/10\n",
      "282/282 [==============================] - 51s 182ms/step - loss: 0.0263 - accuracy: 0.9907 - val_loss: 0.1127 - val_accuracy: 0.9760\n",
      "Epoch 10/10\n",
      "282/282 [==============================] - 46s 163ms/step - loss: 0.0262 - accuracy: 0.9908 - val_loss: 0.1165 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "history = model_wet_solid.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 - 1s - loss: 0.2457 - accuracy: 0.8950\n",
      "Loss = 0.25, Acc = 0.89\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_acc = model_wet_solid.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(f\"Loss = {round(test_loss,2)}, Acc = {round(test_acc,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#打开摄像头\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    # 读取图片\n",
    "    ret, frame = cap.read()\n",
    "    # 展示获取的图片\n",
    "    cv2.imshow(\"capture\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        # 图片写入文件\n",
    "        cv2.imwrite(\"photo.jpg\", frame)\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photo = cv2.imread(\"photo.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "new_photo = cv2.resize(photo, (IMG_SIZE, IMG_SIZE))\n",
    "new_photo = new_photo.reshape(-1,IMG_SIZE, IMG_SIZE, 1)\n",
    "new_photo = new_photo / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predict result is:\",CATEGORIES[model_solid.predict_classes(new_photo)[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
